class(c(PPM)
)
as.numeric(PPM)
houseGols[1].value()
houseGols[1]
as.integer(houseGols[1])
PPM <- list()
for (i in 1:9)
{
for (j in 1:7)
{
tmp <- round(as.integer(houseGols[i])*as.integer(awayGols[j]),2)
PPM <- c(PPM,tmp)
}
}
PPM
PPM <- list()
for (i in 1:9)
{
for (j in 1:7)
{
tmp <- round(as.numeric(houseGols[i])*as.numeric(awayGols[j]),2)
PPM <- c(PPM,tmp)
}
}
PPM
1:10
t(PPM)
list(PPM)
dim(PPM)
shape(PPM)
PPM
PPM[1]
PPM[1,1]
PPM[1][1]
houseGols[1][1]
houseGols[1]
class(houseGols[1])
class(houseGols[1])
PPM <- list()
for (i in 1:9)
{
for (j in 1:7)
{
tmp <- round(as.numeric(houseGols[i][1])*as.numeric(awayGols[j][1]),2)
PPM <- c(PPM,tmp)
}
}
PPM
PPM <- list()
for (i in 1:9)
{
for (j in 1:7)
{
tmp <- round(houseGols[i][1]*awayGols[j][1],2)
PPM <- c(PPM,tmp)
}
}
tmp
PPM
PPM <- list()
for (i in 1:9)
{
for (j in 1:7)
{
tmp <- as.numeric(round(houseGols[i][1]*awayGols[j][1],2))
PPM <- c(PPM,tmp)
}
}
PPM
class(PPM[1])
class(PPM[1][1])
class(PPM[1][1][1])
class(PPM[1][1][1][1])
PPM[1][1]![]
PPM[1][1][1]
PPM[1][1][1][1]
PPM[1][1][1][1][1]
PPM[1][1][1][1][1][1]
as.numeric(round(houseGols[1][1]*awayGols[1][1],2))
# Postwork Sesion 4
# Equipo 12
# **** Recuperando los datos del los postworks anteriores ****
library(dplyr)
library(ggplot2)
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 4/Postwork Files")
lista <- lapply(dir(), read.csv)
lista <- lapply(lista, select, Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR)
lista[[1]] <- mutate(lista[[1]], Date = as.Date(Date, "%d/%m/%y"))
lista[[2]] <- mutate(lista[[2]], Date = as.Date(Date, "%d/%m/%Y"))
lista[[3]] <- mutate(lista[[3]], Date = as.Date(Date, "%d/%m/%Y"))
data <- do.call(rbind, lista)
FTHG <- data$FTHG
FTAG <- data$FTAG
houseGols <- round(table(FTHG)/length(FTHG),2)
awayGols <- round(table(FTAG)/length(FTAG),2)
jointProbability <- round(table(FTHG,FTAG)/length(FTAG),2)
# Desarrollo del Postwork
# 1.- Ya hemos estimado las probabilidades conjuntas de que el equipo de casa anote
#     X=x goles (x=0,1,... ,8), y el equipo visitante anote Y=y goles (y=0,1,... ,6),
#     en un partido. Obtén una tabla de cocientes al dividir estas probabilidades
#     conjuntas por el producto de las probabilidades marginales correspondientes.
# Creación del vector con el producto de las probabilidades marginales
PPM <- list()
for (i in 1:9)
{
for (j in 1:7)
{
tmp <- as.numeric(round(houseGols[i][1]*awayGols[j][1],2))
PPM <- c(PPM,tmp)
}
}
PPM
PPM <- c()
for (i in 1:9)
{
for (j in 1:7)
{
tmp <- as.numeric(round(houseGols[i][1]*awayGols[j][1],2))
PPM <- c(PPM,tmp)
}
}
PPM
jointProbability/PPM
PPM
jointProbability
matrix(PPM,nrow = 9, ncol = 7)
PPM <- c()
for (i in 1:7)
{
for (j in 1:9)
{
tmp <- as.numeric(round(houseGols[j][1]*awayGols[i][1],2))
PPM <- c(PPM,tmp)
}
}
matrix(PPM,nrow = 9, ncol = 7)
jointProbability
jointProbability/PPM
# Postwork Sesion 4
# Equipo 12
# **** Recuperando los datos del los postworks anteriores ****
library(dplyr)
library(ggplot2)
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 4/Postwork Files")
lista <- lapply(dir(), read.csv)
lista <- lapply(lista, select, Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR)
lista[[1]] <- mutate(lista[[1]], Date = as.Date(Date, "%d/%m/%y"))
lista[[2]] <- mutate(lista[[2]], Date = as.Date(Date, "%d/%m/%Y"))
lista[[3]] <- mutate(lista[[3]], Date = as.Date(Date, "%d/%m/%Y"))
data <- do.call(rbind, lista)
FTHG <- data$FTHG
FTAG <- data$FTAG
houseGols <- table(FTHG)/length(FTHG)
awayGols <- table(FTAG)/length(FTAG)
jointProbability <- table(FTHG,FTAG)/length(FTAG)
# Desarrollo del Postwork
# 1.- Ya hemos estimado las probabilidades conjuntas de que el equipo de casa anote
#     X=x goles (x=0,1,... ,8), y el equipo visitante anote Y=y goles (y=0,1,... ,6),
#     en un partido. Obtén una tabla de cocientes al dividir estas probabilidades
#     conjuntas por el producto de las probabilidades marginales correspondientes.
# Creación del vector con el producto de las probabilidades marginales
PPM <- c()
for (i in 1:7)
{
for (j in 1:9)
{
tmp <- as.numeric(round(houseGols[j][1]*awayGols[i][1],2))
PPM <- c(PPM,tmp)
}
}
jointProbability
PPM
# Postwork Sesion 4
# Equipo 12
# **** Recuperando los datos del los postworks anteriores ****
library(dplyr)
library(ggplot2)
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 4/Postwork Files")
lista <- lapply(dir(), read.csv)
lista <- lapply(lista, select, Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR)
lista[[1]] <- mutate(lista[[1]], Date = as.Date(Date, "%d/%m/%y"))
lista[[2]] <- mutate(lista[[2]], Date = as.Date(Date, "%d/%m/%Y"))
lista[[3]] <- mutate(lista[[3]], Date = as.Date(Date, "%d/%m/%Y"))
data <- do.call(rbind, lista)
FTHG <- data$FTHG
FTAG <- data$FTAG
houseGols <- table(FTHG)/length(FTHG)
awayGols <- table(FTAG)/length(FTAG)
jointProbability <- table(FTHG,FTAG)/length(FTAG)
# Desarrollo del Postwork
# 1.- Ya hemos estimado las probabilidades conjuntas de que el equipo de casa anote
#     X=x goles (x=0,1,... ,8), y el equipo visitante anote Y=y goles (y=0,1,... ,6),
#     en un partido. Obtén una tabla de cocientes al dividir estas probabilidades
#     conjuntas por el producto de las probabilidades marginales correspondientes.
# Creación del vector con el producto de las probabilidades marginales
PPM <- c()
for (i in 1:7)
{
for (j in 1:9)
{
tmp <- as.numeric(houseGols[j][1]*awayGols[i][1])
PPM <- c(PPM,tmp)
}
}
jointProbability
PPM
jointProbability
houseGols[1]*awayGols[1]
houseGols[2]*awayGols[2]
# Postwork Sesion 4
# Equipo 12
# **** Recuperando los datos del los postworks anteriores ****
library(dplyr)
library(ggplot2)
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 4/Postwork Files")
lista <- lapply(dir(), read.csv)
lista <- lapply(lista, select, Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR)
lista[[1]] <- mutate(lista[[1]], Date = as.Date(Date, "%d/%m/%y"))
lista[[2]] <- mutate(lista[[2]], Date = as.Date(Date, "%d/%m/%Y"))
lista[[3]] <- mutate(lista[[3]], Date = as.Date(Date, "%d/%m/%Y"))
data <- do.call(rbind, lista)
FTHG <- data$FTHG
FTAG <- data$FTAG
houseGols <-table(FTHG)/length(FTHG)
awayGols <- table(FTAG)/length(FTAG)
jointProbability <- round(table(FTHG,FTAG)/length(FTAG),2)
# Desarrollo del Postwork
# 1.- Ya hemos estimado las probabilidades conjuntas de que el equipo de casa anote
#     X=x goles (x=0,1,... ,8), y el equipo visitante anote Y=y goles (y=0,1,... ,6),
#     en un partido. Obtén una tabla de cocientes al dividir estas probabilidades
#     conjuntas por el producto de las probabilidades marginales correspondientes.
# Creación del vector con el producto de las probabilidades marginales
PPM <- c()
for (i in 1:7)
{
for (j in 1:9)
{
tmp <- as.numeric(round(houseGols[j][1]*awayGols[i][1],2))
PPM <- c(PPM,tmp)
}
}
jointProbability
PPM
jointProbability
matrix(PPM,nrow = 9, ncol = 7)
jointProbability/PPM
(result <- jointProbability/PPM)
result
# Postwork Sesion 4
# Equipo 12
# **** Recuperando los datos del los postworks anteriores ****
library(dplyr)
library(ggplot2)
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 4/Postwork Files")
lista <- lapply(dir(), read.csv)
lista <- lapply(lista, select, Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR)
lista[[1]] <- mutate(lista[[1]], Date = as.Date(Date, "%d/%m/%y"))
lista[[2]] <- mutate(lista[[2]], Date = as.Date(Date, "%d/%m/%Y"))
lista[[3]] <- mutate(lista[[3]], Date = as.Date(Date, "%d/%m/%Y"))
data <- do.call(rbind, lista)
FTHG <- data$FTHG
FTAG <- data$FTAG
houseGols <-table(FTHG)/length(FTHG)
awayGols <- table(FTAG)/length(FTAG)
jointProbability <- table(FTHG,FTAG)/length(FTAG)
# Desarrollo del Postwork
# 1.- Ya hemos estimado las probabilidades conjuntas de que el equipo de casa anote
#     X=x goles (x=0,1,... ,8), y el equipo visitante anote Y=y goles (y=0,1,... ,6),
#     en un partido. Obtén una tabla de cocientes al dividir estas probabilidades
#     conjuntas por el producto de las probabilidades marginales correspondientes.
# Creación del vector con el producto de las probabilidades marginales
PPM <- c()
for (i in 1:7)
{
for (j in 1:9)
{
tmp <- as.numeric(houseGols[j][1]*awayGols[i][1])
PPM <- c(PPM,tmp)
}
}
(result <- jointProbability/PPM)
# 2.- Mediante un procedimiento de boostrap, obtén más cocientes similares a los
#     obtenidos en la tabla del punto anterior. Esto para tener una idea de las
#     distribuciones de la cual vienen los cocientes en la tabla anterior. Menciona
#     en cuáles casos le parece razonable suponer que los cocientes de la tabla en
#     el punto 1, son iguales a 1 (en tal caso tendríamos independencia de las
#     variables aleatorias X y Y).
sum(jointProbability)
sum(PPM)
sum(result)
corr(FTHG,FTAG)
cor(FTHG,FTAG)
plot(cor(FTHG,FTAG))
FTHG
plot(FTAG,FTAG)
plot(FTAG,FTHG)
plot(FTHG,FTAG)
resilt
result
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 5")
production <- read.table("production.txt", header = TRUE)
production <- read.table("production.txt", header = TRUE)
attach(production)
RunTime
plot(RunSize, RunTime, xlab = "TamaÃ±o de ejecuciÃ³n",
ylab = "Tiempo de ejecuciÃ³n", pch = 16)
m1 <- lm(RunTime~RunSize)
summary(m1)
plot(RunSize, RunTime, xlab = "TamaÃ±o de ejecuciÃ³n",
ylab = "Tiempo de ejecuciÃ³n", pch = 16)
abline(lsfit(RunSize, RunTime)) # Trazamos la recta de regresiÃ³n estimada
mtext(expression(paste('Modelo de regresiÃ³n lineal simple:',
' ',
y[i] == beta[0] + beta[1]*x[i] + e[i])),
side = 3, adj=1, font = 2)
text(x = 200, y = 240, expression(paste('Recta de regresiÃ³n:',
' ',
y[i] == beta[0] + beta[1]*x[i])),
adj = 1, font = 2)
text(x = 350, y = 180, expression(paste('Recta estimada:',
' ',
hat(y)[i] == hat(beta)[0] + hat(beta)[1]*x[i])),
adj = 1, font = 2)
text(x = 350, y = 160, expression(paste('Recta estimada:',
' ',
hat(y)[i] == 149.74770 + 0.25924*x[i])),
adj = 1, font = 2)
points(189, 215, pch=16, col = "red") # Punto muestral
149.74770 + 0.25924 * 189 # Valor y sobre la recta estimada
lines(c(189, 189), c(198.7441, 215), col = "red")
points(173, 166, pch=16, col = "red") # Punto muestral
149.74770 + 0.25924 * 173 # Valor y sobre la recta estimada
lines(c(173, 173), c(166, 194.5962), col = "red")
tval <- qt(1-0.05/2, 18)
tval
pt(tval, df = 18)
round(confint(m1, level = 0.95), 3)
1986-1963
1999-1963
2018-1987
(conf <- predict(m1, newdata =
data.frame(RunSize = RunSize0),
interval = "confidence", level = 0.95))
RunSize0 <- c(50,100,150,200,250,300,350) # Algunos posibles valores de RunSize
(conf <- predict(m1, newdata =
data.frame(RunSize = RunSize0),
interval = "confidence", level = 0.95))
lines(RunSize0, conf[, 2], lty = 2, lwd = 2, col = "green") # lÃ­mites inferiores
lines(RunSize0, conf[, 3], lty = 2, lwd = 2, col = "green") # lÃ­mites superiores
(pred <- predict(m1, newdata =
data.frame(RunSize = RunSize0),
interval = "prediction", level = 0.95))
lines(RunSize0, pred[, 2], lty = 2, lwd = 2, col = "blue") # lÃ­mites inferiores
lines(RunSize0, pred[, 3], lty = 2, lwd = 2, col = "blue") # lÃ­mites superiores
anova(m1)
par(mfrow = c(2, 2))
plot(m1)
shapiro.test(m1$residuals)
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 5/Retos Data")
# 1.- Realice el grÃ¡fico de dispersiÃ³n de los datos
read.csv("datoslineal.csv")
# 1.- Realice el grÃ¡fico de dispersiÃ³n de los datos
df <- read.csv("datoslineal.csv")
attach(df)
plot(x,y)
dev.off()
plot(x,y)
# 2.- Ajuste un modelo de regresiÃ³n lineal simple a los datos, muestre un resumen del modelo ajustado y
#     trace la recta de regresiÃ³n estimada junto con el grÃ¡fico de dispersiÃ³n
m1 <- lm(y~x)
summary(m1)
plot(x, y, pch = 16)
abline(lsfit(x,y)) # Trazamos la recta de regresiÃ³n estimada
# 3.- Obtenga algunas grÃ¡ficas de diagnÃ³stico y diga si es razonable suponer para los errores aleatoriedad,
#     normalidad y varianza constante.
anova(m1)
plot(m1)
par(mfrow = c(2, 2))
plot(m1)
var(m1$residuals)
sd(m1$residuals)
shapiro.test(m1$residuals)
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 5")
nyc <- read.csv("nyc.csv", header = TRUE)
head(nyc, 2); tail(nyc, 2); dim(nyc)
attach(nyc)
m1 <- lm(Price ~ Food + Decor + Service + East)
summary(m1)
m2 <- lm(Price ~ Food + Decor + East)
summary(m2)
m2 <- update(m1, ~.-Service)
summary(m2)
~
mfull <- lm(Price ~ Food + Decor + Service + East +
Food:East + Decor:East + Service:East)
mfull <- lm(Price ~ Food + Decor + Service + East +
Food:East + Decor:East + Service:East)
summary(mfull)
anova(m2,mfull)
pairs(~ Food + Decor + Service, data = nyc, gap = 0.4, cex.labels = 1.5)
m1 <- lm(Price ~ Food + Decor + Service + East)
summary(m1)
StanRes1 <- rstandard(m1)
par(mfrow = c(2, 2))
plot(Food, StanRes1, ylab = "Residuales Estandarizados")
plot(Decor, StanRes1, ylab = "Residuales Estandarizados")
plot(Service, StanRes1, ylab = "Residuales Estandarizados")
plot(East, StanRes1, ylab = "Residuales Estandarizados")
dev.off()
plot(m1$fitted.values, Price, xlab = "Valores ajustados", ylab = "Price")
abline(lsfit(m1$fitted.values, Price))
# install.packages("e1071") para instalarlo
library(e1071)
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(e1071)))
suppressMessages(suppressWarnings(library(ggplot2)))
suppressMessages(suppressWarnings(library(ISLR)))
suppressMessages(suppressWarnings(library(ISLR)))
?Default
head(Default)
tail(Default)
dim(Default)
str(Default)
ggplot(Default, aes(x = balance, y = income, colour = default)) +
geom_point() + facet_wrap('student') +
theme_grey() + ggtitle("Datos Default")
set.seed(2020)
train = sample(nrow(Default),
round(nrow(Default)/2))
tail(Default[train, ])
ggplot(Default[train, ],
aes(x = balance, y = income, colour = default)) +
geom_point() + facet_wrap('student') +
theme_dark() + ggtitle("Conjunto de entrenamiento")
ggplot(Default[-train, ],
aes(x = balance, y = income, colour = default)) +
geom_point() + facet_wrap('student') +
theme_light() + ggtitle("Conjunto de prueba")
best <- svm(default~.,  data = Default[train,],
kernel = "radial",
cost = 100,
gamma = 1.51
)
mc <- table(true = Default[-train, "default"],
pred = predict(best,
newdata = Default[-train,]))
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
fit <- svm(default ~ ., data = Default[train,],
kernel = "radial", cost = 100, gamma = 1.51,
decision.values = TRUE)
fitted <- attributes(predict(fit, Default[-train,],
decision.values = TRUE))$decision.values
eti <- ifelse(fitted < 0, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
eti <- ifelse(fitted < 1.002, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
eti <- ifelse(fitted < 1.01, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
eti <- ifelse(fitted < 1.1, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
eti <- ifelse(fitted < 1.05, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
eti <- ifelse(fitted < 1.02, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
