a = 1:20
a[2:4]
vectorSalto = 1:20
vectorSalto * 2
vectorSalto * 2 -1
vectorSalto = 1:20 *2
vectorSalto
1:20+1
1:20*7+15
0:20*7+15
1:10 * 2*11
1:10 * 2:11
The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
a = 1:10
The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
a = 1:10
a
matrix(datos, nrow = 4, ncol = 3)
datos = 1:12
matrix(datos, nrow = 4, ncol = 3)
matrix(datos, nrow = 4, ncol = 4)
a = matrix(datos, nrow = 4, ncol = 3)
a
c(a)
dim(a)
dim(a).ncol
dim(a)[2]
dim(datos)
b = matrix(11:22, nrow = 4, ncol = 3)
a%*%b
b = matrix(11:26, nrow = 4, ncol = 4)
a%*%b
b = matrix(11:26, nrow = 3, ncol = 4)
b = matrix(11:22, nrow = 3, ncol = 4)
a%*%b
a%*%b
c = matrix(1:16, nrow = 4, ncol = 4)
det(c)
c = matrix(4:20, nrow = 4, ncol = 4)
c
c = matrix(4:19, nrow = 4, ncol = 4)
c
det(c)
c = matrix(1:16, nrow = 4, ncol = 4)
t(c)
wich(c==12)
wich(c==12)
resultado = c(1,-2,0)
matrizc = matrix(c(3,2,-1,2,2,0,5,1,4,-1), ncol = 3, nrow = 3)
matrizc
resultado
resultado = as.matrix(c(1,-2,0))
matrizc
resultado
solve(matrizc,resultado)
matrizc = matrix(c(3,2,-1,2,2,0.5,1,4,-1), ncol = 3, nrow = 3)
resultado = as.matrix(c(1,-2,0))
matrizc
resultado
solve(matrizc,resultado)
base = 1:100
base * !(base%%5)
base * (base%%5)
base * (base%%5) * (base%%2) * (base%%3)
base%%2
!base%%2
!base%%5
base * (!base%%2)
base * (base%%2)
base * (base%%2) * (!base%%3)
base[base%%2 != 0 & base%%3 != 0 & base%%5 != 0]
base[base%%2 != 0 & base%%3 != 0 & base%%5 != 0]
entero = 1:20
flotante = 1:20 * 8.5-0.3
caracteres = as.character(entero+64)
df = data.frame("entero" = entero, "flotante" = flotante, "caracteres" = caracteres)
View(df)
# Creacion de vectores
entero = 1:20
flotante = 1:20 * 8.5-0.3
caracteres = as.character(entero)
df = data.frame("entero" = entero, "flotante" = flotante, "caracteres" = caracteres)
View(df)
caracteres = as.character(c(1:20))
caracteres = as.character(c(1:20+3))
caracteres = as.character(entero
caracteres = as.character(entero)
caracteres <- as.character(entero)
# Creacion de vectores
entero = 1:6
flotante = entero * 8.5-0.3
caracteres = as.character(entero)
df = data.frame("entero" = entero, "flotante" = flotante, "caracteres" = caracteres)
as.character(34)
as.character("h")
vector = 1:10
matriz = matrix (c(1:9),ncol = 3, nrow = 3)
lista = list ("vector" = vector, "matriz" = matriz, "DataFrame" = df)
lista["DataFrame"]
dim(lista)
ej1 = c(1:24*2)
ej1
#Ejercicio 2.-
ej2 = c(3)*3
ej2
#Ejercicio 2.-
ej2 = c(3)%*%c(c)
ej2
#Ejercicio 2.-
ej2 = c(3)%*%c(3)
ej2
#Ejercicio 2.-
ej2 = c(3)%+%c(3,3,3)
ej2
#Ejercicio 2.-
ej2 = c(3,3,3,3)
ej2
# Ejercicio 3.-
ej3 = 1:5
ej3
ej4
# Ejercicio 1.-
ej1 = 1:24*2
ej1
# Ejercicio 2.-
ej2 = 1:4 / 1:4 * 3
ej2
1%%4
2%%4
3%%4
4%%4
# Ejercicio 4.-
ej4 = (1:5+1)%4
# Ejercicio 4.-
ej4 = (1:5+1)%%4
ej4
# Ejercicio 4.-
ej4 = (1:5)%%4+1
ej4
# Ejercicio 4.-
ej4 = (1:5+1)%%4+1
ej4
print("Hello World")
install.packages("shiny")
Sys.getenv("PATH")
install.packages("shiny")
(var.hola <- "Hola Mundo")
(var.number <- 5L)
class(var.number)
class(var.hola)
class(var.double)
(var.double <- 2.7076)
class(var.double)
(var.logical <- T)
(vector <- c(1,2))
class(var.logical)
class(var.logical)
typeof(var.logical)
a <- c(4, 6, 8, 10,12)
b <- c(3, 5, 7, 9)
a[1]
b[4]
c(a,b)
sort(c(a,b), decreasing = F)
?sort
3:12  # asÃ­ de sencillo es
(vector.by2 <- seq(from = 1, to = 10, by =2))
(vector.by3 <- seq(1, 10, 3))
(vector.by2 <- seq(from = 2, to = 10, by =2))
rep(a, 2)
rep(5, times = 6)
(vector.by2 <- seq(from = 20, to = 10, by =2))
(vector.by2 <- seq(from = 20, to = 10, by =-2))
c(1, 2) + c(7, 8, 9, 10)
c(7, 8, 9, 10) + c(1,2)
a + b
a - b
a + b
a - b
a*b
a/b
a^2
a1 <- a*0.5 + b^2
a1[1]
a1 <- a*0.5 + b^2
a1
(m <- matrix(1:9, nrow = 3, ncol = 3))
m[ ,1]
(s.vecmat <- c(1, 2) + m)
(n <- matrix(2:7, 4, 6))
matrix(c(1,0),3)
matrix(c(1,0),3,3)
n[n > 4]
which(n > 4)
which(n > 4)
n>4
a <- 2:6
b <- 5:9
cbind(a,b)
rbind(a,b)
apply(n, 1, mean)
apply(n, 2, sort)
b <- 5:8
cbind(a,b)
n
apply(n, 1, mean)
n[1,]
sort(n[1,])
mean(n[1,])
mean(n[2,])
T(A)
t(A)
t(n)
det(n)
det(n)
n[c(1,2,3,4),]
n[,c(1,2,3,4)]
det(n[,c(1,2,3,4)])
n1 <- n[,c(1,2,3,4)]
i(n1)
?inv
?t
?i
solve(n1)
(milista <- list(nombre = "Pepe", no.hijos = 3, edades.hijos = c(4, 7, 9)))
str(milista)
milista$nombre
milista
x <- 6:8
y <- c("A", "B", "C")
(mifile <- data.frame(edad = x, grupo = y))
str(mifile)
mifile[1]
mifile[,1]
mifile$edad
mifile[1,]
mifile[,2]
mean(mifile$edad)
paste("La media de la edad es:", mean(mifile$edad))
summary(mifile)
mifile$sexo <- c("H", "M", "H")
mifile
mifile$sexo <- NULL
mifile
getwd()
read.csv("bestsellers with categories.csv") # El archivo csv debe estar en el directorio de trabajo
amazon.books <- read.csv("bestsellers with categories.csv")
tail(amazon.books); str(amazon.books)
data.url <- read.csv("https://www.football-data.co.uk/mmz4281/2021/SP1.csv")
data.url
head(data.url)
str(data.url)
# Reto 1
# 1.- Leer el archivo "netflix_titles.csv" desde GitHub
netflix.titles <- read.csv("https://raw.githubusercontent.com/ecoronadoj/Sesion_1/main/Data/netflix_titles.csv")
# 2.- Obtener la dimensión y el tipo de objeto que se obtiene
dim(netflix.titles); class(netflix.titles)
summary(netflix.titles)
str(netflix.titles)
netflix.titles[netflix.titles$release_year>2015]
wich(netflix.titles$release_year>2015)
witch(netflix.titles$release_year>2015)
which(netflix.titles$release_year>2015)
netflix.titles$release_year>2015
netflic[netflix.titles$release_year>2015]
netflix.titles[netflix.titles$release_year>2015]
which(netflix.titles$release_year>2015)
cols <- which(netflix.titles$release_year>2015)
class(cols)
cols
dim(cols)
lenght(cols)
length(cols)
netflix.titles[cols]
netflix.titles[,cols]
netflix.titles[,1]
netflix.titles[cols,]
net.2015 <- netflix.titles[cols,]
write.csv(net.2015)
?write.csv
write.csv(net.2015,file = res.netflix.csv)
write.csv(net.2015,file = "res.netflix.csv")
library(ggplot2) # Se omite el uso de las comillas
install.packages("ggplot2") #siempre lleva  comillas
install.packages("dplyr")
library(dplyr)
library(ggplot2) # Se omite el uso de las comillas
w <- rnorm(20)
print("Este loop calcula el cuadrado de los 10 primeros elementos del vector w")
wsq <- 0
for(i in 1:10) {
wsq[i] <- w[i]**2
print(wsq[i])
}
w <- rnorm(20)
print("Este loop calcula el cuadrado de los 10 primeros elementos del vector w")
wsq <- 0
for(i in 1:10) {
wsq[i] <- w[i]**2
print(wsq[i])
}
w
w**2
rep(2,3)
rep("hola",3)
?runif
(ran <- rnorm(44))
ran1 <- 0
for (i in 1:15)
ran1[i] <- ran[i]**3 + 12
ran1 <- 0
for (i in 1:15)
{
ran1[i] <- ran[i]**3 + 12
}
ran1
(df.al <- data.frame(ran = ran[1:15], ran1 = ran1))
amazon.best <- read.csv("https://raw.githubusercontent.com/ecoronadoj/Sesion_1/main/Data/bestsellers%20with%20categories.csv")
# 2.- Calcula el data frame transpuesto, asígnale el nombre de tAmazon y conviértelo en un data frame
tAmazon <- t(amazon.best)
tAmazon
1/0
?mean
??mean
?setwd
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 2")
getwd()
x = c(4000, 9000, 9000, 10000); mean(x)
median(x)
library(DescTools)
Mode(x) # mode es diferente de Mode (Case sensitive)
?mode()
x <- c(29, 13, 62, 4, 63, 96, 1, 90, 50, 46)
quantile(x, 0.25) # cuantil del 25%
quantile(x, c(0.25,0.50,0.75)) # Cuartiles
quantile(x, c(0.25,0.50,0.75)) # Cuartiles
quantile(x, seq(0.1,0.9, by = 0.1)) # Deciles
IQR(x)
IQR(x)
quantile(x, probs = 0.75) - quantile(x, probs = 0.25)
var(x)
sd(x)
set.seed(134)
x <- round(rnorm(1000, 175, 6), 1)
#1.- Calcule, la media, mediana y moda de los valores en x
mean(x)
library(DescTool)
library(DescTools)
Mode(x)
#2.- Obtenga los deciles de los números en x
quantile(x, seq(0.1,0.9, by = 0.1))
#3.- Encuentre la rango intercuartílico, la desviación estándar y varianza muestral de las mediciones en x
IQR(x)
sd(x)
var(x)
mtcars
str(mtcars)
summary(mtcars)
head(mtcars)
View(mtcars)
str(iris)
summary(1:100)
summary(mtcars)
set.seed(57)
x <- rnorm(35)
e <- rnorm(35)
y <- 5 + 2*x + e
modelo <- lm(y~x)
summary(modelo)
head(mtcars)
tail(mtcars)
View(iris)
suppressMessages(suppressWarnings(library(dplyr)))
url1 <- "https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv"
url2 <- "https://data.humdata.org/hxlproxy/data/download/time_series_covid19_deaths_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv"
download.file(url = url1, destfile = "st19ncov-confirmados.csv", mode = "wb")
download.file(url = url2, destfile = "st19ncov-muertes.csv", mode = "wb")
download.file(url = url2, destfile = "st19ncov-muertes.csv", mode = "wb")
conf <- read.csv("st19ncov-confirmados.csv")
mu <- read.csv("st19ncov-muertes.csv")
str(conf); str(mu)
head(conf); head(mu)
Sconf <- conf[-1,]
Smu <- mu[-1,]
Sconf <- select(Sconf, Country.Region, Date, Value) # PaÃ­s, fecha y acumulado de infectados
Sconf <- rename(Sconf, Country = Country.Region, Infectados = Value)
str(Sconf)
Sconf <- mutate(Sconf, Date = as.Date(Date, "%Y-%m-%d"), Infectados = as.numeric(as.character(Infectados)))
Smu <- select(Smu, Country.Region, Date, Value) # Seleccionamos paÃ­s, fecha y acumulado de muertos
Smu <- rename(Smu, Country = Country.Region, Muertos = Value) # Renombramos
Smu <- mutate(Smu, Date = as.Date(Date, "%Y-%m-%d"), Muertos = as.numeric(as.character(Muertos))) # Transformamos
Scm <- merge(Sconf, Smu) # Unimos infectados y muertos acumulados para cada fecha
str(Scm)
mex <- filter(Scm, Country == "Mexico") # Seleccionamos sÃ³lo a MÃ©xico
mex <- filter(mex, Infectados != 0) # Primer dÃ­a de infectados
View(mex)
mex <- mutate(mex, NI = c(1, diff(Infectados))) # Nuevos infectados por dÃ­a
mex <- mutate(mex, NM = c(0, diff(Muertos))) # Nuevos muertos por dÃ­a
mex <- mutate(mex, Letalidad = round(Muertos/Infectados*100, 1)) # Tasa de letalidad
mex <- mutate(mex, IDA = lag(Infectados), MDA = lag(Muertos)) # Valores dÃ­a anterior
mex <- mutate(mex, FCI = Infectados/IDA, FCM = Muertos/MDA) # Factores de Crecimiento
mex <- mutate(mex, Dia = 1:dim(mex)[1]) # DÃ­as de contingencia
head(mex); tail(mex)
View(mex)
diff(mex)
diff(mex.Infectados)
diff(mex$Infectados)
plot(mex$NI, type = "l")
plot(mex$NM, type = "l")
plot(mex$Infectados, type = "l")
cbind(1:10, 11:20, 21:30)
cbind(1:10, matrix(11:30, ncol =2))
cbind(data.frame(x = 1:10, y = 11:20), z = 21:30)
df1 <- data.frame(x = 1:5, y = 6:10, z = 16:20)
df2 <- data.frame(x = 51:55, y = 101:105, z = 151:155)
df1; df2
rbind(df1, df2)
X <- matrix(1:49, ncol = 7)
X
apply(X, 1, mean) # cÃ¡lculo de la media para las filas
apply(X, 2, median) # cÃ¡lculo de la mediana para las columnas
u1011 <- "https://www.football-data.co.uk/mmz4281/1011/SP1.csv"
u1112 <- "https://www.football-data.co.uk/mmz4281/1112/SP1.csv"
u1213 <- "https://www.football-data.co.uk/mmz4281/1213/SP1.csv"
u1314 <- "https://www.football-data.co.uk/mmz4281/1314/SP1.csv"
download.file(url = u1011, destfile = "SP1-1011.csv", mode = "wb")
download.file(url = u1112, destfile = "SP1-1112.csv", mode = "wb")
download.file(url = u1011, destfile = "SP1-1011.csv", mode = "wb")
download.file(url = u1213, destfile = "SP1-1213.csv", mode = "wb")
download.file(url = u1314, destfile = "SP1-1314.csv", mode = "wb")
dir()
setw("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 2/SP1")
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 2/SP1")
dir()
lista <- lapply(dir(), read.csv) # Guardamos los archivos en lista
library(dplyr)
dir()
head(lista[[1]]); head(lista[[2]]); head(lista[[3]]); head(lista[[4]])
lista
head(lista[[1]]); head(lista[[2]]); head(lista[[3]]); head(lista[[4]])
lista <- lapply(lista, select, Date:FTR) # seleccionamos solo algunas columnas de cada data frame
head(lista[[1]]); head(lista[[2]]); head(lista[[3]]); head(lista[[4]])
data <- do.call(rbind, lista)
head(data)
dim(data)
1520/4
?do.call
setwd("C:/Users/alana/Documents/GitHub/Data-Science/Modulo 2/Sesion 2/Dataset Reto")
# 2.-Importe los archivos descargados a R
lista <- lapply(dir(), read.csv)
str(lista)
head(lista[[1]]); head(lista[[2]]); head(lista[[3]]); head(lista[[4]])
#Date
#HomeTeam
#AwayTeam
#FTHG
#FTAG
#FTR
lista <- lapply(lista, select, Date:FTR)
head(lista[[1]]); head(lista[[2]]); head(lista[[3]]); head(lista[[4]])
# 2.-Importe los archivos descargados a R
lista <- lapply(dir(), read.csv)
#Date
#HomeTeam
#AwayTeam
#FTHG
#FTAG
#FTR
lista <- lapply(lista, select, Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR)
head(lista[[1]]); head(lista[[2]]); head(lista[[3]]); head(lista[[4]])
# 4.-Combine cada uno de los data frames en un único data frame con ayuda de las funciones:
#rbind
#do.call
data <- do.call(rbind, lista)
View(data)
str(data)
data <- mutate(data, Date = as.Date(Date, "%d-%m-%Y")
data <- mutate(data, Date = as.Date(Date, "%d-%m-%Y"))
library(rjson)
library(XML)
library(rjson)
library(XML)
URL1 <- "https://tools.learningcontainer.com/sample-json-file.json"
#URL1 <- "http://www.ipab.org.mx/ipab/datosabiertos?od=02-21"
JsonData <- fromJSON(file = URL1)
class(JsonData)
length(JsonData)
str(JsonData)
URL2 <- "http://www-db.deis.unibo.it/courses/TW/DOCS/w3schools/xml/cd_catalog.xml"
#URL2 <- "http://www.ipab.org.mx/ipab/datosabiertos?od=03-21"
xmlfile <- xmlTreeParse(URL2) # Parse the XML file. Analizando el XML
topxml <- xmlSApply(xmlfile, function(x) xmlSApply(x, xmlValue)) # Mostrando los datos de una forma amigable
xml_df <- data.frame(t(topxml), row.names= NULL) # Colocandolos en un Data Frame
str(xml_df) # Observar la naturaleza de las variables del DF
head(xml_df)
url3 <- URL2 # cargue el URL del XML
data_df <- xmlToDataFrame(url3)
head(data_df)
head(airquality)
library(dplyr)
str(airquality)
dim(airquality)
bien <- complete.cases(airquality)
sum(bien)
airquality[bien,]
data <- select(airquality, Ozone:Temp)
apply(data, 2, mean)
apply(data, 2, mean, na.rm = T)
(m1 <- apply(na.omit(data), 2, mean))
b <- complete.cases(data)
(m2 <- apply(data[b,], 2, mean))
identical(m1, m2)
